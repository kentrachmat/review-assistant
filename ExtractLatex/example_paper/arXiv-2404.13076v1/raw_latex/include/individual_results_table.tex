\begin{table}[h]
    \centering
    \begin{tabular}{l|ccccc}
                                       & \multicolumn{5}{c}{Target Source} \\ 
    Evaluator Model                    & GPT-4 & GPT-3.5 & Llama & Human & Claude-2 \\
    \hline
    GPT-4                              & 0.5        & 0.526      & 0.638      & 0.71       & 0.561      \\
    GPT-3.5                            & 0.5        & 0.5        & 0.514      & 0.581      & 0.505      \\
    Llama-2-7b                         & 0.495      & 0.498      & 0.5        & 0.502      & 0.495      \\
    \multicolumn{6}{c}{} \\
    \multicolumn{6}{c}{\textbf{GPT-3.5 Fine-Tuning Runs on XSUM (In-Domain)}} \\
    Self-Recognition (2 examples)              & 0.499      & 0.5        & 0.523      & 0.634      & 0.513      \\
    Self-Recognition (10 examples)             & 0.499      & 0.5        & 0.54       & 0.67       & 0.522      \\
    Self-Recognition (500 examples)            & 0.519      & 0.5        & 0.582      & 0.778      & 0.597      \\
    Always 1                           & 0.498      & 0.5        & 0.503      & 0.499      & 0.498      \\
    Random                             & 0.5        & 0.5        & 0.505      & 0.501      & 0.499      \\
    Readability                        & 0.494      & 0.5        & 0.528      & 0.609      & 0.52       \\
    Length                             & 0.499      & 0.5        & 0.509      & 0.6        & 0.517      \\
    Vowel count                        & 0.499      & 0.5        & 0.519      & 0.653      & 0.514      \\
    \multicolumn{6}{c}{} \\
    \multicolumn{6}{c}{\textbf{GPT-3.5 Fine-Tuning Runs on CNN (Out-of-Domain)}} \\
    Self-Recognition (2 examples)              & 0.498      & 0.5        & 0.529      & 0.631      & 0.508      \\
    Self-Recognition (10 examples)             & 0.501      & 0.5        & 0.522      & 0.608      & 0.508      \\
    Self-Recognition (500 examples)            & 0.539      & 0.5        & 0.627      & 0.892      & 0.691      \\
    Always 1                           & 0.501      & 0.5        & 0.502      & 0.504      & 0.499      \\
    Random                             & 0.5        & 0.5        & 0.502      & 0.505      & 0.501      \\
    Readability                        & 0.498      & 0.5        & 0.521      & 0.576      & 0.509      \\
    Length                             & 0.5        & 0.5        & 0.535      & 0.669      & 0.519      \\
    Vowel count                        & 0.482      & 0.5        & 0.564      & 0.742      & 0.523      \\
    \multicolumn{6}{c}{} \\
    \multicolumn{6}{c}{\textbf{Llama-2-7b Fine-Tuning Runs on XSUM (In-Domain)}} \\
    Self-Recognition (2 examples)              & 0.495      & 0.502      & 0.5        & 0.501      & 0.497      \\
    Self-Recognition (10 examples)             & 0.496      & 0.499      & 0.5        & 0.505      & 0.498      \\
    Self-Recognition (500 examples)            & 0.49       & 0.491      & 0.5        & 0.514      & 0.483      \\
    Always 1                           & 0.5        & 0.5        & 0.5        & 0.5        & 0.5        \\
    Random                             & 0.498      & 0.499      & 0.5        & 0.502      & 0.497      \\
    Readability                        & 0.496      & 0.498      & 0.5        & 0.497      & 0.496      \\
    Length                             & 0.502      & 0.496      & 0.5        & 0.478      & 0.493      \\
    Vowel count                        & 0.493      & 0.493      & 0.5        & 0.497      & 0.495      \\
    \multicolumn{6}{c}{} \\
    \multicolumn{6}{c}{\textbf{Llama-2-7b Fine-Tuning Runs on CNN (Out-of-Domain)}} \\
    Self-Recognition (2 examples)              & 0.497      & 0.501      & 0.5        & 0.507      & 0.497      \\
    Self-Recognition (10 examples)             & 0.499      & 0.499      & 0.5        & 0.506      & 0.499      \\
    Self-Recognition (500 examples)            & 0.499      & 0.494      & 0.5        & 0.499      & 0.494      \\
    Always 1                           & 0.5        & 0.5        & 0.5        & 0.5        & 0.5        \\
    Random                             & 0.5        & 0.499      & 0.5        & 0.496      & 0.499      \\
    Readability                        & 0.499      & 0.496      & 0.5        & 0.499      & 0.495      \\
    Vowel count                        & 0.501      & 0.497      & 0.5        & 0.495      & 0.503      \\
    \end{tabular}
    \caption{Self-Recognition confidence scores in the individual setting, evaluated on the XSUM dataset.}
    \label{table:individual_self_rec_xsum}
\end{table}


\begin{table}[h]
    \centering
    \begin{tabular}{l|ccccc}
                                       & \multicolumn{5}{c}{Target Source} \\ 
    Evaluator Model                    & GPT-4 & GPT-3.5 & Llama & Human & Claude-2 \\
    \hline
    \multicolumn{6}{c}{\textbf{No Fine-Tuning}} \\
    GPT-4                              & 0.5         & 0.51        & 0.534       & 0.596       & 0.514       \\
    GPT-3.5                            & 0.496       & 0.5         & 0.503       & 0.528       & 0.499       \\
    Llama-2-7b                         & 0.499       & 0.5         & 0.5         & 0.501       & 0.499       \\
    \multicolumn{6}{c}{} \\
    \multicolumn{6}{c}{\textbf{GPT-3.5 Fine-Tuning Runs on XSUM (In-Domain)}} \\
    Self-Recognition (2 examples)              & 0.497       & 0.5         & 0.507       & 0.536       & 0.502       \\
    Self-Recognition (10 examples)             & 0.498       & 0.5         & 0.506       & 0.537       & 0.502       \\
    Self-Recognition (500)                     & 0.527       & 0.5         & 0.581       & 0.753       & 0.598       \\
    Always 1                           & 0.499       & 0.5         & 0.501       & 0.504       & 0.502       \\
    Random                             & 0.499       & 0.5         & 0.501       & 0.504       & 0.502       \\
    Readability                        & 0.481       & 0.5         & 0.521       & 0.617       & 0.516       \\
    Length                             & 0.499       & 0.5         & 0.506       & 0.517       & 0.505       \\
    Vowel count                        & 0.496       & 0.5         & 0.512       & 0.545       & 0.503       \\
    \multicolumn{6}{c}{} \\
    \multicolumn{6}{c}{\textbf{GPT-3.5 Fine-Tuning Runs on CNN (Out-of-Domain)}} \\
    Self-Recognition (2)                       & 0.497       & 0.5         & 0.507       & 0.54        & 0.503       \\
    Self-Recognition (10)                      & 0.497       & 0.5         & 0.508       & 0.541       & 0.504       \\
    Self-Recognition (500)                     & 0.498       & 0.5         & 0.525       & 0.658       & 0.521       \\
    Always 1                           & 0.499       & 0.5         & 0.503       & 0.524       & 0.502       \\
    Random                             & 0.498       & 0.5         & 0.502       & 0.513       & 0.5         \\
    Readability                        & 0.481       & 0.5         & 0.526       & 0.623       & 0.498       \\
    Length                             & 0.495       & 0.5         & 0.51        & 0.541       & 0.501       \\
    Vowel count                        & 0.495       & 0.5         & 0.513       & 0.578       & 0.502       \\
    \multicolumn{6}{c}{} \\
    \multicolumn{6}{c}{\textbf{Llama-2-7b Fine-Tuning Runs on XSUM (In-Domain)}} \\
    Self-Recognition (2)                       & 0.5         & 0.5         & 0.5         & 0.502       & 0.499       \\
    Self-Recognition (10)                      & 0.499       & 0.5         & 0.5         & 0.502       & 0.499       \\
    Self-Recognition (500)                     & 0.497       & 0.5         & 0.5         & 0.518       & 0.502       \\
    Always 1                           & 0.495       & 0.496       & 0.5         & 0.504       & 0.509       \\
    Random                             & 0.498       & 0.499       & 0.5         & 0.503       & 0.499       \\
    Readability                        & 0.497       & 0.499       & 0.5         & 0.502       & 0.499       \\
    Length                             & 0.498       & 0.499       & 0.5         & 0.503       & 0.498       \\
    Vowel count                        & 0.498       & 0.499       & 0.5         & 0.503       & 0.499       \\
    \multicolumn{6}{c}{} \\
    \multicolumn{6}{c}{\textbf{Llama-2-7b Fine-Tuning Runs on CNN (Out-of-Domain)}} \\
    Self-Recognition (2)                       & 0.501       & 0.501       & 0.5         & 0.502       & 0.5         \\
    Self-Recognition (10)                      & 0.5         & 0.5         & 0.5         & 0.503       & 0.499       \\
    Self-Recognition (500)                     & 0.499       & 0.5         & 0.5         & 0.502       & 0.5         \\
    Always 1                           & 0.5         & 0.5         & 0.5         & 0.499       & 0.5         \\
    Random                             & 0.5         & 0.5         & 0.5         & 0.501       & 0.5         \\
    Readability                        & 0.5         & 0.5         & 0.5         & 0.499       & 0.5         \\
    Vowel count                        & 0.499       & 0.499       & 0.5         & 0.498       & 0.499       \\
    \end{tabular}
    \caption{Self-preference scores in the individual setting, evaluated on the XSUM dataset.}
    \label{table:individual_self_pref_xsum}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{l|ccccc}
                                           & \multicolumn{5}{c}{Target Source} \\ 
        Evaluator Model                    & GPT-4 & GPT-3.5 & Llama & Human & Claude-2 \\
        \hline
        \multicolumn{6}{c}{\textbf{No Fine-Tuning}} \\
        GPT-4                              & 0.5        & 0.602      & 0.619      & 0.715      & 0.634      \\
        GPT-3.5                            & 0.493      & 0.5        & 0.502      & 0.518      & 0.498      \\
        Llama-2-7b                         & 0.501      & 0.495      & 0.5        & 0.495      & 0.503      \\
        \multicolumn{6}{c}{} \\
        \multicolumn{6}{c}{\textbf{GPT-3.5 Fine-Tuning Runs on XSUM (Out-of-Domain)}} \\
        Self-Recognition (2 examples)              & 0.491      & 0.5        & 0.501      & 0.53       & 0.503      \\
        Self-Recognition (10 examples)             & 0.492      & 0.5        & 0.503      & 0.54       & 0.507      \\
        Self-Recognition (500)                     & 0.495      & 0.5        & 0.506      & 0.671      & 0.607      \\
        Always 1                           & 0.49       & 0.5        & 0.493      & 0.495      & 0.495      \\
        Random                             & 0.488      & 0.5        & 0.492      & 0.492      & 0.494      \\
        Readability                        & 0.507      & 0.5        & 0.53       & 0.568      & 0.531      \\
        Length                             & 0.502      & 0.5        & 0.507      & 0.541      & 0.511      \\
        Vowel count                        & 0.5        & 0.5        & 0.5        & 0.508      & 0.501      \\
        \multicolumn{6}{c}{} \\
        \multicolumn{6}{c}{\textbf{GPT-3.5 Fine-Tuning Runs on CNN (In-Domain)}} \\
        Self-Recognition (2)                       & 0.484      & 0.5        & 0.49       & 0.516      & 0.494      \\
        Self-Recognition (10)                      & 0.49       & 0.5        & 0.495      & 0.525      & 0.498      \\
        Self-Recognition (500)                     & 0.721      & 0.5        & 0.723      & 0.888      & 0.806      \\
        Always 1                           & 0.497      & 0.5        & 0.5        & 0.501      & 0.502      \\
        Random                             & 0.498      & 0.5        & 0.501      & 0.501      & 0.5        \\
        Readability                        & 0.489      & 0.5        & 0.507      & 0.543      & 0.508      \\
        Length                             & 0.505      & 0.5        & 0.519      & 0.544      & 0.517      \\
        Vowel count                        & 0.497      & 0.5        & 0.499      & 0.544      & 0.508      \\
        \multicolumn{6}{c}{} \\
        \multicolumn{6}{c}{\textbf{Llama-2-7b Fine-Tuning Runs on XSUM (Out-of-Domain)}} \\
        Self-Recognition (2)                       & 0.504      & 0.494      & 0.5        & 0.492      & 0.505      \\
        Self-Recognition (10)                      & 0.505      & 0.497      & 0.5        & 0.501      & 0.51       \\
        Self-Recognition (500)                     & 0.503      & 0.484      & 0.5        & 0.463      & 0.491      \\
        Always 1                           & 0.5        & 0.5        & 0.5        & 0.5        & 0.5        \\
        Random                             & 0.501      & 0.498      & 0.5        & 0.498      & 0.502      \\
        Readability                        & 0.498      & 0.499      & 0.5        & 0.496      & 0.502      \\
        Length                             & 0.5        & 0.474      & 0.5        & 0.467      & 0.488      \\
        Vowel count                        & 0.509      & 0.48       & 0.5        & 0.481      & 0.497      \\
        \multicolumn{6}{c}{} \\
        \multicolumn{6}{c}{\textbf{Llama-2-7b Fine-Tuning Runs on CNN (In-Domain)}} \\
        Self-Recognition (2)                       & 0.5        & 0.497      & 0.5        & 0.499      & 0.501      \\
        Self-Recognition (10)                      & 0.502      & 0.498      & 0.5        & 0.5        & 0.506      \\
        Self-Recognition (500)                     & 0.508      & 0.501      & 0.5        & 0.499      & 0.502      \\
        Always 1                           & 0.5        & 0.5        & 0.5        & 0.5        & 0.5        \\
        Random                             & 0.501      & 0.5        & 0.5        & 0.5        & 0.501      \\
        Readability                        & 0.511      & 0.508      & 0.5        & 0.518      & 0.504      \\
        Vowel count                        & 0.5        & 0.503      & 0.5        & 0.502      & 0.505      \\
    \end{tabular}

    \caption{Self-recognition confidence scores in the individual setting, evaluated on the CNN dataset.}
    \label{table:individual_self_rec_cnn}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{l|ccccc}
                                           & \multicolumn{5}{c}{Target Source} \\ 
        Evaluator Model                    & GPT-4 & GPT-3.5 & Llama & Human & Claude-2 \\
        \hline
        \multicolumn{6}{c}{\textbf{No Fine-Tuning}} \\
        GPT-4                              & 0.5         & 0.516       & 0.52        & 0.536       & 0.518       \\
        GPT-3.5                            & 0.492       & 0.5         & 0.502       & 0.516       & 0.499       \\
        Llama-2-7b                         & 0.5         & 0.501       & 0.5         & 0.502       & 0.501       \\
        \multicolumn{6}{c}{} \\
        \multicolumn{6}{c}{\textbf{GPT-3.5 Fine-Tuning Runs on XSUM (Out-of-Domain)}} \\
        Self-Recognition (2 examples)              & 0.492       & 0.5         & 0.503       & 0.52        & 0.502       \\
        Self-Recognition (10 examples)             & 0.494       & 0.5         & 0.502       & 0.518       & 0.502       \\
        Self-Recognition (500)                     & 0.536       & 0.5         & 0.537       & 0.602       & 0.578       \\
        Always 1                           & 0.499       & 0.5         & 0.501       & 0.501       & 0.5         \\
        Random                             & 0.499       & 0.5         & 0.501       & 0.501       & 0.5         \\
        Readability                        & 0.496       & 0.5         & 0.53        & 0.577       & 0.524       \\
        Length                             & 0.489       & 0.5         & 0.5         & 0.52        & 0.503       \\
        Vowel count                        & 0.49        & 0.5         & 0.501       & 0.518       & 0.503       \\
        \multicolumn{6}{c}{} \\
        \multicolumn{6}{c}{\textbf{GPT-3.5 Fine-Tuning Runs on CNN (In-Domain)}} \\
        Self-Recognition (2)                       & 0.494       & 0.5         & 0.503       & 0.521       & 0.503       \\
        Self-Recognition (10)                      & 0.495       & 0.5         & 0.505       & 0.525       & 0.504       \\
        Self-Recognition (500)                     & 0.494       & 0.5         & 0.512       & 0.625       & 0.538       \\
        Always 1                           & 0.499       & 0.5         & 0.5         & 0.505       & 0.5         \\
        Random                             & 0.494       & 0.5         & 0.499       & 0.505       & 0.499       \\
        Readability                        & 0.467       & 0.5         & 0.5         & 0.579       & 0.499       \\
        Length                             & 0.481       & 0.5         & 0.489       & 0.514       & 0.494       \\
        Vowel count                        & 0.496       & 0.5         & 0.497       & 0.514       & 0.5         \\
        \multicolumn{6}{c}{} \\
        \multicolumn{6}{c}{\textbf{Llama-2-7b Fine-Tuning Runs on XSUM (Out-of-Domain)}} \\
        Self-Recognition (2)                       & 0.5         & 0.501       & 0.5         & 0.502       & 0.501       \\
        Self-Recognition (10)                      & 0.5         & 0.501       & 0.5         & 0.501       & 0.501       \\
        Self-Recognition (500)                     & 0.496       & 0.501       & 0.5         & 0.508       & 0.498       \\
        Always 1                           & 0.5         & 0.487       & 0.5         & 0.516       & 0.479       \\
        Random                             & 0.5         & 0.5         & 0.5         & 0.503       & 0.5         \\
        Readability                        & 0.5         & 0.5         & 0.5         & 0.502       & 0.5         \\
        Length                             & 0.5         & 0.5         & 0.5         & 0.501       & 0.5         \\
        Vowel count                        & 0.499       & 0.5         & 0.5         & 0.501       & 0.5         \\
        \multicolumn{6}{c}{} \\
        \multicolumn{6}{c}{\textbf{Llama-2-7b Fine-Tuning Runs on CNN (In-Domain)}} \\
        Self-Recognition (2)                       & 0.5         & 0.5         & 0.5         & 0.502       & 0.501       \\
        Self-Recognition (10)                      & 0.5         & 0.5         & 0.5         & 0.502       & 0.5         \\
        Self-Recognition (500)                     & 0.498       & 0.499       & 0.5         & 0.498       & 0.499       \\
        Always 1                           & 0.5         & 0.5         & 0.5         & 0.5         & 0.5         \\
        Random                             & 0.5         & 0.5         & 0.5         & 0.5         & 0.5         \\
        Readability                        & 0.501       & 0.499       & 0.5         & 0.498       & 0.499       \\
        Vowel count                        & 0.501       & 0.501       & 0.5         & 0.501       & 0.502       \\
    \end{tabular}
    \caption{Self-recognition confidence scores in the individual setting, evaluated on the CNN dataset.}
    \label{table:individual_self_pref_cnn}
\end{table}