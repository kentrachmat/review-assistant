@article{pan2024feedback,
  title={Feedback Loops With Language Models Drive In-Context Reward Hacking},
  author={Pan, Alexander and Jones, Erik and Jagadeesan, Meena and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2402.06627},
  year={2024}
}

@article{ai2022whodunit,
  title={Whodunit? learning to contrast for authorship attribution},
  author={Ai, Bo and Wang, Yuchen and Tan, Yugin and Tan, Samson},
  journal={arXiv preprint arXiv:2209.11887},
  year={2022}
}

@article{yang2023survey,
  title={A survey on detection of llms-generated content},
  author={Yang, Xianjun and Pan, Liangming and Zhao, Xuandong and Chen, Haifeng and Petzold, Linda and Wang, William Yang and Cheng, Wei},
  journal={arXiv preprint arXiv:2310.15654},
  year={2023}
}

@article{kumarage2024survey,
  title={A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization},
  author={Kumarage, Tharindu and Agrawal, Garima and Sheth, Paras and Moraffah, Raha and Chadha, Aman and Garland, Joshua and Liu, Huan},
  journal={arXiv preprint arXiv:2403.01152},
  year={2024}
}

@article{chen2023can,
  title={Can llm-generated misinformation be detected?},
  author={Chen, Canyu and Shu, Kai},
  journal={arXiv preprint arXiv:2309.13788},
  year={2023}
}

@article{hans2024spotting,
  title={Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text},
  author={Hans, Abhimanyu and Schwarzschild, Avi and Cherepanova, Valeriia and Kazemi, Hamid and Saha, Aniruddha and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2401.12070},
  year={2024}
}

@article{xu2024perils,
  title={Perils of Self-Feedback: Self-Bias Amplifies in Large Language Models},
  author={Xu, Wenda and Zhu, Guanglei and Zhao, Xuandong and Pan, Liangming and Li, Lei and Wang, William Yang},
  journal={arXiv preprint arXiv:2402.11436},
  year={2024}
}

@article{wu2023survey,
  title={A survey on llm-gernerated text detection: Necessity, methods, and future directions},
  author={Wu, Junchao and Yang, Shu and Zhan, Runzhe and Yuan, Yulin and Wong, Derek F and Chao, Lidia S},
  journal={arXiv preprint arXiv:2310.14724},
  year={2023}
}

@article{jawahar2020automatic,
  title={Automatic detection of machine generated text: A critical survey},
  author={Jawahar, Ganesh and Abdul-Mageed, Muhammad and Lakshmanan, Laks VS},
  journal={arXiv preprint arXiv:2011.01314},
  year={2020}
}

@article{crothers2023machine,
  title={Machine-generated text: A comprehensive survey of threat models and detection methods},
  author={Crothers, Evan and Japkowicz, Nathalie and Viktor, Herna L},
  journal={IEEE Access},
  year={2023},
  publisher={IEEE}
}

@inproceedings{mitchell2023detectgpt,
  title={Detectgpt: Zero-shot machine-generated text detection using probability curvature},
  author={Mitchell, Eric and Lee, Yoonho and Khazatsky, Alexander and Manning, Christopher D and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={24950--24962},
  year={2023},
  organization={PMLR}
}

@article{tang2023science,
  title={The science of detecting llm-generated texts},
  author={Tang, Ruixiang and Chuang, Yu-Neng and Hu, Xia},
  journal={arXiv preprint arXiv:2303.07205},
  year={2023}
}

@article{berglund2023taken,
  title={Taken out of context: On measuring situational awareness in LLMs},
  author={Berglund, Lukas and Stickland, Asa Cooper and Balesni, Mikita and Kaufmann, Max and Tong, Meg and Korbak, Tomasz and Kokotajlo, Daniel and Evans, Owain},
  journal={arXiv preprint arXiv:2309.00667},
  year={2023}
}

@article{wang2023large,
  title={Large Language Model Situational Awareness Based Planning},
  author={Wang, Liman and Zhong, Hanyang},
  journal={arXiv preprint arXiv:2312.16127},
  year={2023}
}

@article{wang2024mm,
  title={MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of Multimodal Large Language Models in Perception},
  author={Wang, Yuhao and Liao, Yusheng and Liu, Heyang and Liu, Hongcheng and Wang, Yu and Wang, Yanfeng},
  journal={arXiv preprint arXiv:2401.07529},
  year={2024}
}

@article{amayuelas2023knowledge,
  title={Knowledge of knowledge: Exploring known-unknowns uncertainty with large language models},
  author={Amayuelas, Alfonso and Pan, Liangming and Chen, Wenhu and Wang, William},
  journal={arXiv preprint arXiv:2305.13712},
  year={2023}
}

@article{yin2023large,
  title={Do Large Language Models Know What They Don't Know?},
  author={Yin, Zhangyue and Sun, Qiushi and Guo, Qipeng and Wu, Jiawen and Qiu, Xipeng and Huang, Xuanjing},
  journal={arXiv preprint arXiv:2305.18153},
  year={2023}
}

@article{kadavath2022language,
  title={Language models (mostly) know what they know},
  author={Kadavath, Saurav and Conerly, Tom and Askell, Amanda and Henighan, Tom and Drain, Dawn and Perez, Ethan and Schiefer, Nicholas and Hatfield-Dodds, Zac and DasSarma, Nova and Tran-Johnson, Eli and others},
  journal={arXiv preprint arXiv:2207.05221},
  year={2022}
}

@inproceedings{laine2023towards,
  title={Towards a situational awareness benchmark for LLMs},
  author={Laine, Rudolf and Meinke, Alexander and Evans, Owain},
  booktitle={Socially Responsible Language Modelling Research},
  year={2023}
}

@article{koo2023benchmarking,
  title={Benchmarking cognitive biases in large language models as evaluators},
  author={Koo, Ryan and Lee, Minhwa and Raheja, Vipul and Park, Jong Inn and Kim, Zae Myung and Kang, Dongyeop},
  journal={arXiv preprint arXiv:2309.17012},
  year={2023}
}

@article{raina2024llm,
  title={Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on Zero-shot LLM Assessment},
  author={Raina, Vyas and Liusie, Adian and Gales, Mark},
  journal={arXiv preprint arXiv:2402.14016},
  year={2024}
}

@article{zheng2024judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{bai2024benchmarking,
  title={Benchmarking foundation models with language-model-as-an-examiner},
  author={Bai, Yushi and Ying, Jiahao and Cao, Yixin and Lv, Xin and He, Yuze and Wang, Xiaozhi and Yu, Jifan and Zeng, Kaisheng and Xiao, Yijia and Lyu, Haozhe and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{bitton2023visit,
  title={Visit-bench: A benchmark for vision-language instruction following inspired by real-world use},
  author={Bitton, Yonatan and Bansal, Hritik and Hessel, Jack and Shao, Rulin and Zhu, Wanrong and Awadalla, Anas and Gardner, Josh and Taori, Rohan and Schimdt, Ludwig},
  journal={Advances in Neural Information Processing Systems},
  year={2023}
}

@article{fleschNewReadabilityYardstick1948,
	title = {A new readability yardstick},
	volume = {32},
	issn = {1939-1854},
	doi = {10.1037/h0057532},
	abstract = {The author provides a revised system for determining the comprehension difficulty of written material through the use of two new formulae which measure reading ease and human interest. The following elements are used in analyzing text passages: (1) average sentence length in words; (2) average word length in syllables; (3) average percentage of "personal words"; (4) average percentage of personal sentences. A step-by-step procedure for using the formulae, and interpretative table of scores, and an analysis of passages in "Life" and "The New Yorker" are given. 20-item bibliography. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {3},
	journal = {Journal of Applied Psychology},
	author = {Flesch, Rudolph},
	year = {1948},
	note = {Place: US
Publisher: American Psychological Association},
	keywords = {Commerce, Comprehension, Interests, Readability, Reading Comprehension, Sentences},
	pages = {221--233},
	file = {Flesch_1948_A new readability yardstick.pdf:C\:\\Users\\arjun\\Zotero\\storage\\XB5RE82P\\Flesch_1948_A new readability yardstick.pdf:application/pdf;Snapshot:C\:\\Users\\arjun\\Zotero\\storage\\I5TNKQFY\\1949-01274-001.html:text/html},
}

@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research direction},
  author={Leike, Jan and Krueger, David and Everitt, Tom and Martic, Miljan and Maini, Vishal and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{shridhar2023art,
  title={The art of llm refinement: Ask, refine, and trust},
  author={Shridhar, Kumar and Sinha, Koustuv and Cohen, Andrew and Wang, Tianlu and Yu, Ping and Pasunuru, Ram and Sachan, Mrinmaya and Weston, Jason and Celikyilmaz, Asli},
  journal={arXiv preprint arXiv:2311.07961},
  year={2023}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{openai2023gpt4,
      title={{GPT-4} Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      journal={arXiv preprint arXiv:2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{wu2021recursively,
  title={Recursively summarizing books with human feedback},
  author={Wu, Jeff and Ouyang, Long and Ziegler, Daniel M and Stiennon, Nisan and Lowe, Ryan and Leike, Jan and Christiano, Paul},
  journal={arXiv preprint arXiv:2109.10862},
  year={2021}
}

@article{stiennon2020learning,
  title={Learning to summarize with human feedback},
  author={Stiennon, Nisan and Ouyang, Long and Wu, Jeffrey and Ziegler, Daniel and Lowe, Ryan and Voss, Chelsea and Radford, Alec and Amodei, Dario and Christiano, Paul F},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={3008--3021},
  year={2020}
}

@article{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{see2017get,
  title={Get to the point: Summarization with pointer-generator networks},
  author={See, Abigail and Liu, Peter J and Manning, Christopher D},
  journal={arXiv preprint arXiv:1704.04368},
  year={2017}
}

@article{narayan2018don,
  title={Don't give me the details, just the summary! topic-aware convolutional neural networks for extreme summarization},
  author={Narayan, Shashi and Cohen, Shay B and Lapata, Mirella},
  journal={arXiv preprint arXiv:1808.08745},
  year={2018}
}

@article{madaan2023self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2303.17651},
  year={2023}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@article{lee2023rlaif,
  title={{RLAIF}: Scaling reinforcement learning from human feedback with ai feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav},
  journal={arXiv preprint arXiv:2309.00267},
  year={2023}
}