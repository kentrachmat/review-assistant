% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@misc{hariharan2024rethinkingcybersecevalllmaidedapproach,
      title={Rethinking CyberSecEval: An LLM-Aided Approach to Evaluation Critique}, 
      author={Suhas Hariharan and Zainab Ali Majid and Jaime Raldua Veuthey and Jacob Haimes},
      year={2024},
      eprint={2411.08813},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2411.08813}, 
}

@misc{haimes2024benchmarkinflationrevealingllm,
      title={Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts}, 
      author={Jacob Haimes and Cenny Wenner and Kunvar Thaman and Vassil Tashev and Clement Neo and Esben Kran and Jason Schreiber},
      year={2024},
      eprint={2410.09247},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.09247}, 
}

@misc{anurin2024catastrophiccybercapabilitiesbenchmark,
      title={Catastrophic Cyber Capabilities Benchmark (3CB): Robustly Evaluating LLM Agent Cyber Offense Capabilities}, 
      author={Andrey Anurin and Jonathan Ng and Kibo Schaffer and Jason Schreiber and Esben Kran},
      year={2024},
      eprint={2410.09114},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2410.09114}, 
}
@misc{li2024wmdp,
title={The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning},
author={Nathaniel Li and Alexander Pan and Anjali Gopal and Summer Yue and Daniel Berrios and Alice Gatti and Justin D. Li and Ann-Kathrin Dombrowski and Shashwat Goel and Long Phan and Gabriel Mukobi and Nathan Helm-Burger and Rassin Lababidi and Lennart Justen and Andrew B. Liu and Michael Chen and Isabelle Barrass and Oliver Zhang and Xiaoyuan Zhu and Rishub Tamirisa and Bhrugu Bharathi and Adam Khoja and Zhenqi Zhao and Ariel Herbert-Voss and Cort B. Breuer and Samuel Marks and Oam Patel and Andy Zou and Mantas Mazeika and Zifan Wang and Palash Oswal and Weiran Liu and Adam A. Hunt and Justin Tienken-Harder and Kevin Y. Shih and Kemper Talley and John Guan and Russell Kaplan and Ian Steneker and David Campbell and Brad Jokubaitis and Alex Levinson and Jean Wang and William Qian and Kallol Krishna Karmakar and Steven Basart and Stephen Fitz and Mindy Levine and Ponnurangam Kumaraguru and Uday Tupakula and Vijay Varadharajan and Yan Shoshitaishvili and Jimmy Ba and Kevin M. Esvelt and Alexandr Wang and Dan Hendrycks},
year={2024},
eprint={2403.03218},
archivePrefix={arXiv},
primaryClass={cs.LG}
}
@misc{gade2024badllamacheaplyremovingsafety,
      title={BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B}, 
      author={Pranav Gade and Simon Lermen and Charlie Rogers-Smith and Jeffrey Ladish},
      year={2024},
      eprint={2311.00117},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.00117}, 
}
@misc{perez2022red,
      title={Red Teaming Language Models with Language Models}, 
      author={Ethan Perez and Saffron Huang and Francis Song and Trevor Cai and Roman Ring and John Aslanides and Amelia Glaese and Nat McAleese and Geoffrey Irving},
      year={2022},
      eprint={2202.03286},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ganguli2022red,
      title={Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned}, 
      author={Deep Ganguli and Liane Lovitt and Jackson Kernion and Amanda Askell and Yuntao Bai and Saurav Kadavath and Ben Mann and Ethan Perez and Nicholas Schiefer and Kamal Ndousse and Andy Jones and Sam Bowman and Anna Chen and Tom Conerly and Nova DasSarma and Dawn Drain and Nelson Elhage and Sheer El-Showk and Stanislav Fort and Zac Hatfield-Dodds and Tom Henighan and Danny Hernandez and Tristan Hume and Josh Jacobson and Scott Johnston and Shauna Kravec and Catherine Olsson and Sam Ringer and Eli Tran-Johnson and Dario Amodei and Tom Brown and Nicholas Joseph and Sam McCandlish and Chris Olah and Jared Kaplan and Jack Clark},
      year={2022},
      eprint={2209.07858},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{lewis2021retrievalaugmented,
      title={Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks}, 
      author={Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
      year={2021},
      eprint={2005.11401},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}
@misc{bai2022training,
      title={Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback}, 
      author={Yuntao Bai and Andy Jones and Kamal Ndousse and Amanda Askell and Anna Chen and Nova DasSarma and Dawn Drain and Stanislav Fort and Deep Ganguli and Tom Henighan and Nicholas Joseph and Saurav Kadavath and Jackson Kernion and Tom Conerly and Sheer El-Showk and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Tristan Hume and Scott Johnston and Shauna Kravec and Liane Lovitt and Neel Nanda and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Ben Mann and Jared Kaplan},
      year={2022},
      eprint={2204.05862},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}
@misc{qin2023toolllm,
      title={ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs}, 
      author={Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Lauren Hong and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
      year={2023},
      eprint={2307.16789},
      archivePrefix={arXiv},
      primaryClass={id='cs.AI' full_name='Artificial Intelligence' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers all areas of AI except Vision, Robotics, Machine Learning, Multiagent Systems, and Computation and Language (Natural Language Processing), which have separate subject areas. In particular, includes Expert Systems, Theorem Proving (although this may overlap with Logic in Computer Science), Knowledge Representation, Planning, and Uncertainty in AI. Roughly includes material in ACM Subject Classes I.2.0, I.2.1, I.2.3, I.2.4, I.2.8, and I.2.11.'}
}
@article{bonicalzi_artificial_2023,
	title = {Artificial {Intelligence} and {Autonomy}: {On} the {Ethical} {Dimension} of {Recommender} {Systems}},
	volume = {42},
	issn = {1572-8749},
	shorttitle = {Artificial {Intelligence} and {Autonomy}},
	url = {https://doi.org/10.1007/s11245-023-09922-5},
	doi = {10.1007/s11245-023-09922-5},
	abstract = {Feasting on a plethora of social media platforms, news aggregators, and online marketplaces, recommender systems (RSs) are spreading pervasively throughout our daily online activities. Over the years, a host of ethical issues have been associated with the diffusion of RSs and the tracking and monitoring of users’ data. Here, we focus on the impact RSs may have on personal autonomy as the most elusive among the often-cited sources of grievance and public outcry. On the grounds of a philosophically nuanced notion of autonomy, we illustrate three specific reasons why RSs may limit or compromise it: the threat of manipulation and deception associated with RSs; the RSs’ power to reshape users’ personal identity; the impact of RSs on knowledge and critical thinking. In our view, however, notwithstanding these legitimate concerns, RSs may effectively help users to navigate an otherwise overwhelming landscape. Our perspective, therefore, is not to be intended as a bulwark to protect the status quo but as an invitation to carefully weigh these aspects in the design of ethically oriented RSs.},
	language = {en},
	number = {3},
	urldate = {2024-06-16},
	journal = {Topoi},
	author = {Bonicalzi, Sofia and De Caro, Mario and Giovanola, Benedetta},
	month = jul,
	year = {2023},
	keywords = {Artificial intelligence, Autonomy, Identity, Reasons-responsiveness, Recommender systems, Reflective-endorsement},
	pages = {819--832},
	file = {Full Text PDF:/Users/esben/Zotero/storage/ZTIX93D7/Bonicalzi et al. - 2023 - Artificial Intelligence and Autonomy On the Ethic.pdf:application/pdf},
}

@misc{mitelut_intent-aligned_2023,
	title = {Intent-aligned {AI} systems deplete human agency: the need for agency foundations research in {AI} safety},
	shorttitle = {Intent-aligned {AI} systems deplete human agency},
	url = {http://arxiv.org/abs/2305.19223},
	doi = {10.48550/arXiv.2305.19223},
	abstract = {The rapid advancement of artificial intelligence (AI) systems suggests that artificial general intelligence (AGI) systems may soon arrive. Many researchers are concerned that AIs and AGIs will harm humans via intentional misuse (AI-misuse) or through accidents (AI-accidents). In respect of AI-accidents, there is an increasing effort focused on developing algorithms and paradigms that ensure AI systems are aligned to what humans intend, e.g. AI systems that yield actions or recommendations that humans might judge as consistent with their intentions and goals. Here we argue that alignment to human intent is insufficient for safe AI systems and that preservation of long-term agency of humans may be a more robust standard, and one that needs to be separated explicitly and a priori during optimization. We argue that AI systems can reshape human intention and discuss the lack of biological and psychological mechanisms that protect humans from loss of agency. We provide the first formal definition of agency-preserving AI-human interactions which focuses on forward-looking agency evaluations and argue that AI systems - not humans - must be increasingly tasked with making these evaluations. We show how agency loss can occur in simple environments containing embedded agents that use temporal-difference learning to make action recommendations. Finally, we propose a new area of research called "agency foundations" and pose four initial topics designed to improve our understanding of agency in AI-human interactions: benevolent game theory, algorithmic foundations of human rights, mechanistic interpretability of agency representation in neural-networks and reinforcement learning from internal states.},
	urldate = {2024-06-16},
	publisher = {arXiv},
	author = {Mitelut, Catalin and Smith, Ben and Vamplew, Peter},
	month = may,
	year = {2023},
	note = {arXiv:2305.19223 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction},
	file = {arXiv Fulltext PDF:/Users/esben/Zotero/storage/VYYP7LJD/Mitelut et al. - 2023 - Intent-aligned AI systems deplete human agency th.pdf:application/pdf},
}

@article{krippendorff_computing_2011,
	title = {Computing {Krippendorff}'s {Alpha}-{Reliability}},
	url = {https://repository.upenn.edu/handle/20.500.14332/2089},
	abstract = {Krippendorff’s alpha (α) is a reliability coefficient developed to measure the agreement among observers, coders, judges, raters, or measuring instruments drawing distinctions among typically unstructured phenomena or assign computable values to them. α emerged in content analysis but is widely applicable wherever two or more methods of generating data are applied to the same set of objects, units of analysis, or items and the question is how much the resulting data can be trusted to represent something real.},
	language = {en},
	number = {43},
	urldate = {2024-06-16},
	author = {Krippendorff, Klaus},
	month = jan,
	year = {2011},
	file = {Full Text PDF:/Users/esben/Zotero/storage/N8JCVYN9/Krippendorff - 2011 - Computing Krippendorff's Alpha-Reliability.pdf:application/pdf},
}

@article{griffiths_simulated_2012,
	title = {Simulated gambling in video gaming: {What} are the implications for adolescents?},
	volume = {30},
	issn = {2049-3665},
	shorttitle = {Simulated gambling in video gaming},
	url = {http://www.scopus.com/inward/record.url?scp=84872474926&partnerID=8YFLogxK},
	abstract = {Recent empirical research studies suggests that children and adolescents access online gambling activities using digital devices such as personal computers, laptops, smartphones, and other portable devices (e.g., Griffiths \& Parke, 2010; King, Delfabbro, \& Griffiths, 2010). Three national adolescent gambling surveys carried out for the National Lottery Commission in Great Britain (Griffiths \& Wood, 2007; Ipsos MORI, 2009; 2011) have all shown that a small minority of children and adolescents can and do gamble online. The most recent study (Ipsos MORI, 2011) reported that 2\% of 11-16 year olds had played online lottery games and 2\% had gambled on other online games (i.e., online casinos, online poker, online bingo and/or online sports betting). These data suggest that the first gambling experiences by some children and adolescents might occur via the Internet, mobile phones, and/or interactive television rather than in a traditional offline gaming venue such as a casino, amusement arcade or bookmakers (Griffiths, 2011).},
	number = {3},
	urldate = {2024-06-16},
	journal = {Education and Health},
	author = {Griffiths, Mark D. and King, Daniel L. and Delfabbro, Paul H.},
	month = dec,
	year = {2012},
	pages = {68--70},
	annote = {E\&H was first published in 1983 and is now an open access journal which means that all content is freely available without charge to the user or his/her institution. Users are allowed to read, download, copy, distribute, print, search, or link to the full texts of the articles in this journal without asking prior permission from the publisher or the author. This is in accordance with the BOAI definition of open access and follows the principles of the Creative Commons licence CC-BY-NC-ND 3.0 [Licence extract : Share — copy and redistribute the material in any medium or format.  NonCommercial — You may not use the material for commercial purposes. NoDerivatives — If you remix, transform, or build upon the material, you may not distribute the modified material.] There are no contributor fees and copyright remains with the contributor. The contributor allows their work to be edited prior to publishing.},
}

@misc{noauthor_pln-fing-udelarfast-krippendorff_2024,
	title = {pln-fing-udelar/fast-krippendorff},
	copyright = {GPL-3.0},
	url = {https://github.com/pln-fing-udelar/fast-krippendorff},
	abstract = {Fast computation of Krippendorff's alpha agreement measure in Python.},
	urldate = {2024-06-16},
	publisher = {Grupo PLN, UdelaR},
	month = jun,
	year = {2024},
	note = {original-date: 2017-09-28T03:47:34Z},
	keywords = {agreement, alpha, coders, inter-annotator-agreement, krippendorff, reliability, reliability-rating, units, values},
}

@article{Jia_2024,
   title={Embedding Democratic Values into Social Media AIs via Societal Objective Functions},
   volume={8},
   ISSN={2573-0142},
   url={http://dx.doi.org/10.1145/3641002},
   DOI={10.1145/3641002},
   number={CSCW1},
   journal={Proceedings of the ACM on Human-Computer Interaction},
   publisher={Association for Computing Machinery (ACM)},
   author={Jia, Chenyan and Lam, Michelle S. and Mai, Minh Chau and Hancock, Jeffrey T. and Bernstein, Michael S.},
   year={2024},
   month=apr, pages={1–36} }


@misc{openai2024gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji et al.},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{metr2024evals,
	title = {Measuring the impact of post-training enhancements},
	url = {https://metr.github.io/autonomy-evals-guide/elicitation-gap/},
	abstract = {Resources for testing dangerous autonomous capabilities in frontier models},
	language = {en},
	urldate = {2024-06-08},
        year={2024},
        author={METR},
	journal = {METR’s Autonomy Evaluation Resources},
	file = {Snapshot:/Users/esben/Zotero/storage/SA8SJL3Q/elicitation-gap.html:text/html},
}


@misc{jimenez2024swebench,
      title={SWE-bench: Can Language Models Resolve Real-World GitHub Issues?}, 
      author={Carlos E. Jimenez and John Yang and Alexander Wettig and Shunyu Yao and Kexin Pei and Ofir Press and Karthik Narasimhan},
      year={2024},
      eprint={2310.06770},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{pan2023rewards,
      title={Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark}, 
      author={Alexander Pan and Jun Shern Chan and Andy Zou and Nathaniel Li and Steven Basart and Thomas Woodside and Jonathan Ng and Hanlin Zhang and Scott Emmons and Dan Hendrycks},
      year={2023},
      eprint={2304.03279},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{hendrycks2021measuring,
      title={Measuring Massive Multitask Language Understanding}, 
      author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
      year={2021},
      eprint={2009.03300},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}

@misc{siegel2024probabilities,
      title={The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models}, 
      author={Noah Y. Siegel and Oana-Maria Camburu and Nicolas Heess and Maria Perez-Ortiz},
      year={2024},
      eprint={2404.03189},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tian2023finetuning,
      title={Fine-tuning Language Models for Factuality}, 
      author={Katherine Tian and Eric Mitchell and Huaxiu Yao and Christopher D. Manning and Chelsea Finn},
      year={2023},
      eprint={2311.08401},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {$L_1$}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
  url={https://dl.acm.org/doi/abs/10.1145/1273496.1273501}
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK},
    url={https://www.cambridge.org/core/books/algorithms-on-strings-trees-and-sequences/F0B095049C7E6EF5356F0A26686C20D3}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005},
	url={https://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf}
}

@article{ct1965,
  title={An algorithm for the machine calculation of complex {F}ourier series},
  author={Cooley, James W. and Tukey, John W.},
  journal={Mathematics of Computation},
  volume={19},
  number={90},
  pages={297--301},
  year={1965},
  url={https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}



@misc{park2024,
 title={Seemingly Human: Dark Patterns in ChatGPT},
   author={Park, Jin Suk and Lu, Angela and Kran, Esben},
   year={2024},
   organization={Apart Research},
   note={Research submission to the MASec research sprint hosted by Apart.},
   month={February},
   howpublished={https://apartresearch.com}
}


@inproceedings{
scheurer2024large,
title={Large Language Models can Strategically Deceive their Users when Put Under Pressure},
author={J{\'e}r{\'e}my Scheurer and Mikita Balesni and Marius Hobbhahn},
booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
year={2024},
url={https://openreview.net/forum?id=HduMpot9sJ}
}

@misc{brignull-2023,
author = {Brignull, H and Leiser, M and Santos, C and Doshi, K},
month = {4},
title = {{Deceptive patterns – user interfaces designed to trick you}},
year = {2023},
url = {https://www.deceptive.design/},
}

@article{brignull2010dark,
  title={Dark Patterns.(2010)},
  author={Brignull, Harry and Darlo, A},
  journal={URL: https://www. darkpatterns. org/(visited on 02/09/2019)(cited on p. 23)},
  year={2010}
}


@article{Bhargava_Velasquez_2021, title={Ethics of the Attention Economy: The Problem of Social Media Addiction}, volume={31}, DOI={10.1017/beq.2020.32}, number={3}, journal={Business Ethics Quarterly}, author={Bhargava, Vikram R. and Velasquez, Manuel}, year={2021}, pages={321–359}}

@misc{anderson2010,
title = {Why Google keeps your data forever, tracks you with ads},
author = {Anderson, Nate},
year = {2010},
url = {https://arstechnica.com/tech-policy/2010/03/google-keeps-your-data-to-learn-from-good-guys-fight-off-bad-guys/}
}







@article{Zuboff2015,
author = {Shoshana Zuboff},
title ={Big other: Surveillance Capitalism and the Prospects of an Information Civilization},
year = {2015},
journal = {Journal of Information Technology},
volume = {30},
number = {1},
pages = {75-89},
year = {2015},
doi = {10.1057/jit.2015.5},

URL = { 
    
        https://doi.org/10.1057/jit.2015.5
    
    

}
}


@article{truthfulqa,
  author       = {Stephanie Lin and
                  Jacob Hilton and
                  Owain Evans},
  title        = {TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  journal      = {CoRR},
  volume       = {abs/2109.07958},
  year         = {2021},
  url          = {https://arxiv.org/abs/2109.07958},
  eprinttype    = {arXiv},
  eprint       = {2109.07958},
  timestamp    = {Wed, 22 Sep 2021 14:16:57 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2109-07958.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{Mathur_2021, series={CHI ’21},
   title={What Makes a Dark Pattern... Dark?: Design Attributes, Normative Considerations, and Measurement Methods},
   url={http://dx.doi.org/10.1145/3411764.3445610},
   DOI={10.1145/3411764.3445610},
   booktitle={Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
   publisher={ACM},
   author={Mathur, Arunesh and Kshirsagar, Mihir and Mayer, Jonathan},
   year={2021},
   month=may, collection={CHI ’21} }


@article{verena2023,
author = {Traubinger, Verena and Heil, Sebastian and Grigera, Julián and Garrido, Alejandra and Gaedke, Martin},
year = {2023},
month = {11},
pages = {},
title = {In Search of Dark Patterns in Chatbots},
doi = {10.13140/RG.2.2.16643.27683}
}


@inproceedings{nehring-etal-2024-large-language,
    title = "Large Language Models Are Echo Chambers",
    author = {Nehring, Jan  and
      Gabryszak, Aleksandra  and
      J{\"u}rgens, Pascal  and
      Burchardt, Aljoscha  and
      Schaffer, Stefan  and
      Spielkamp, Matthias  and
      Stark, Birgit},
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.884",
    pages = "10117--10123"
}


@misc{benharrak2024deceptive,
      title={Deceptive Patterns of Intelligent and Interactive Writing Assistants}, 
      author={Karim Benharrak and Tim Zindulka and Daniel Buschek},
      year={2024},
      eprint={2404.09375},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}


@inproceedings{colin2018,
author = {Gray, Colin M. and Kou, Yubo and Battles, Bryan and Hoggatt, Joseph and Toombs, Austin L.},
title = {The Dark (Patterns) Side of UX Design},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174108},
doi = {10.1145/3173574.3174108},
pages = {1–14},
series = {CHI '18}
}


@inproceedings{deshpande-etal-2023-anthropomorphization,
    title = "Anthropomorphization of {AI}: Opportunities and Risks",
    author = "Deshpande, Ameet  and
      Rajpurohit, Tanmay  and
      Narasimhan, Karthik  and
      Kalyan, Ashwin",
    editor = "Preo{\textcommabelow{t}}iuc-Pietro, Daniel  and
      Goanta, Catalina  and
      Chalkidis, Ilias  and
      Barrett, Leslie  and
      Spanakis, Gerasimos (Jerry)  and
      Aletras, Nikolaos",
    booktitle = "Proceedings of the Natural Legal Language Processing Workshop 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.nllp-1.1",
    doi = "10.18653/v1/2023.nllp-1.1",
    pages = "1--7",
}


@inproceedings{Zhang_2024, series={CHI ’24},
   title={“It’s a Fair Game”, or Is It? Examining How Users Navigate Disclosure Risks and Benefits When Using LLM-Based Conversational Agents},
   url={http://dx.doi.org/10.1145/3613904.3642385},
   DOI={10.1145/3613904.3642385},
   booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
   publisher={ACM},
   author={Zhang, Zhiping and Jia, Michelle and Lee, Hao-Ping (Hank) and Yao, Bingsheng and Das, Sauvik and Lerner, Ada and Wang, Dakuo and Li, Tianshi},
   year={2024},
   month=may, collection={CHI ’24} }


@inproceedings{kentrell2022,
author = {Owens, Kentrell and Gunawan, Johanna and Choffnes, David and Emami-Naeini, Pardis and Kohno, Tadayoshi and Roesner, Franziska},
title = {Exploring Deceptive Design Patterns in Voice Interfaces},
year = {2022},
isbn = {9781450397001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549015.3554213},
doi = {10.1145/3549015.3554213},
booktitle = {Proceedings of the 2022 European Symposium on Usable Security},
pages = {64–78},
numpages = {15},
series = {EuroUSEC '22}
}

@INPROCEEDINGS{9074420,
  author={Nagarhalli, Tatwadarshi P. and Vaze, Vinod and Rana, N. K.},
  booktitle={2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={A Review of Current Trends in the Development of Chatbot Systems}, 
  year={2020},
  volume={},
  number={},
  pages={706-710},
  keywords={Natural language processing;Machine learning;Robots;Task analysis;Communication systems;Chatbot;Chatbot Systems;Dialogue Systems;Conversation Systems;Natural Language Processing;Machine Learning;Chatbot Knowledge;Chatbot Domain},
  doi={10.1109/ICACCS48705.2020.9074420}}

@misc{chatgptusage,
author = {Chad Brooks},
title={With Little Employer Oversight, ChatGPT Usage Rates Rise Among American Workers},
year={2023},
url={https://www.business.com/technology/chatgpt-usage-workplace-study/}
}

@misc{veselovsky2023prevalence,
      title={Prevalence and prevention of large language model use in crowd work}, 
      author={Veniamin Veselovsky and Manoel Horta Ribeiro and Philip Cozzolino and Andrew Gordon and David Rothschild and Robert West},
      year={2023},
      eprint={2310.15683},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{sharegpt,
title={ShareGPT90K},
author={RyokoAI},
url={https://huggingface.co/datasets/RyokoAI/ShareGPT52K}
}

@misc{zhao2024wildchat,
      title={WildChat: 1M ChatGPT Interaction Logs in the Wild}, 
      author={Wenting Zhao and Xiang Ren and Jack Hessel and Claire Cardie and Yejin Choi and Yuntian Deng},
      year={2024},
      eprint={2405.01470},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{park2023ai,
      title={AI Deception: A Survey of Examples, Risks, and Potential Solutions}, 
      author={Peter S. Park and Simon Goldstein and Aidan O'Gara and Michael Chen and Dan Hendrycks},
      year={2023},
      eprint={2308.14752},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}

@misc{sharma2023understanding,
      title={Towards Understanding Sycophancy in Language Models}, 
      author={Mrinank Sharma and Meg Tong and Tomasz Korbak and David Duvenaud and Amanda Askell and Samuel R. Bowman and Newton Cheng and Esin Durmus and Zac Hatfield-Dodds and Scott R. Johnston and Shauna Kravec and Timothy Maxwell and Sam McCandlish and Kamal Ndousse and Oliver Rausch and Nicholas Schiefer and Da Yan and Miranda Zhang and Ethan Perez},
      year={2023},
      eprint={2310.13548},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{järviniemi2024uncovering,
      title={Uncovering Deceptive Tendencies in Language Models: A Simulated Company AI Assistant}, 
      author={Olli Järviniemi and Evan Hubinger},
      year={2024},
      eprint={2405.01576},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{panickssery2024llm,
      title={LLM Evaluators Recognize and Favor Their Own Generations}, 
      author={Arjun Panickssery and Samuel R. Bowman and Shi Feng},
      year={2024},
      eprint={2404.13076},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{nikhilgenerative,
author = {Sharma, Nikhil and Liao, Q. Vera and Xiao, Ziang},
title = {Generative Echo Chamber? Effect of LLM-Powered Search Systems on Diverse Information Seeking},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642459},
doi = {10.1145/3613904.3642459},
booktitle = {Proceedings of the CHI Conference on Human Factors in Computing Systems},
articleno = {1033},
numpages = {17},
keywords = {Confirmation Bias, Conversational Search, Echo Chamber Effect, Generative AI, Information Diversity, Information Seeking, Large Language Models},
series = {CHI '24}
}

@article{corina2020,
author = {Cara, Corina},
year = {2020},
url={https://seaopenresearch.eu/Journals/articles/NIS_14_3.pdf},
book={Network Intelligence Studies},
volume={Volume VII},
title = {DARK PATTERNS IN THE MEDIA: A SYSTEMATIC REVIEW}
}


@misc{ouyang2022training,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{bai2022constitutional,
      title={Constitutional AI: Harmlessness from AI Feedback}, 
      author={Yuntao Bai and Saurav Kadavath and Sandipan Kundu and Amanda Askell and Jackson Kernion and Andy Jones and Anna Chen and Anna Goldie and Azalia Mirhoseini and Cameron McKinnon and Carol Chen and Catherine Olsson and Christopher Olah and Danny Hernandez and Dawn Drain and Deep Ganguli and Dustin Li and Eli Tran-Johnson and Ethan Perez and Jamie Kerr and Jared Mueller and Jeffrey Ladish and Joshua Landau and Kamal Ndousse and Kamile Lukosuite and Liane Lovitt and Michael Sellitto and Nelson Elhage and Nicholas Schiefer and Noemi Mercado and Nova DasSarma and Robert Lasenby and Robin Larson and Sam Ringer and Scott Johnston and Shauna Kravec and Sheer El Showk and Stanislav Fort and Tamera Lanham and Timothy Telleen-Lawton and Tom Conerly and Tom Henighan and Tristan Hume and Samuel R. Bowman and Zac Hatfield-Dodds and Ben Mann and Dario Amodei and Nicholas Joseph and Sam McCandlish and Tom Brown and Jared Kaplan},
      year={2022},
      eprint={2212.08073},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{alberts2024computers,
      title={Computers as Bad Social Actors: Dark Patterns and Anti-Patterns in Interfaces that Act Socially}, 
      author={Lize Alberts and Ulrik Lyngs and Max Van Kleek},
      year={2024},
      eprint={2302.04720},
      archivePrefix={arXiv},
      primaryClass={cs.HC}
}



@article{10.1145/3359183,
author = {Mathur, Arunesh and Acar, Gunes and Friedman, Michael J. and Lucherini, Eli and Mayer, Jonathan and Chetty, Marshini and Narayanan, Arvind},
title = {Dark Patterns at Scale: Findings from a Crawl of 11K Shopping Websites},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359183},
doi = {10.1145/3359183},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {81},
numpages = {32}
}


@inproceedings{Casper_2024, series={FAccT ’24},
   title={Black-Box Access is Insufficient for Rigorous AI Audits},
   url={http://dx.doi.org/10.1145/3630106.3659037},
   DOI={10.1145/3630106.3659037},
   booktitle={The 2024 ACM Conference on Fairness, Accountability, and Transparency},
   publisher={ACM},
   author={Casper, Stephen and Ezell, Carson and Siegmann, Charlotte and Kolt, Noam and Curtis, Taylor Lynn and Bucknall, Benjamin and Haupt, Andreas and Wei, Kevin and Scheurer, Jérémy and Hobbhahn, Marius and Sharkey, Lee and Krishna, Satyapriya and Von Hagen, Marvin and Alberti, Silas and Chan, Alan and Sun, Qinyi and Gerovitch, Michael and Bau, David and Tegmark, Max and Krueger, David and Hadfield-Menell, Dylan},
   year={2024},
   month=jun, collection={FAccT ’24} }



@inproceedings{geronimowheretofind,
author = {Di Geronimo, Linda and Braz, Larissa and Fregnan, Enrico and Palomba, Fabio and Bacchelli, Alberto},
title = {UI Dark Patterns and Where to Find Them: A Study on Mobile Applications and User Perception},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376600},
doi = {10.1145/3313831.3376600},
pages = {1–14},
numpages = {14},
series = {CHI '20}
}


@article{llama3modelcard,

title={Llama 3 Model Card},


author={AI@Meta},

year={2024},

url = {https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md}

}


@misc{jiang2024mixtral,
      title={Mixtral of Experts}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Antoine Roux and Arthur Mensch and Blanche Savary and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Emma Bou Hanna and Florian Bressand and Gianna Lengyel and Guillaume Bour and Guillaume Lample and Lélio Renard Lavaud and Lucile Saulnier and Marie-Anne Lachaux and Pierre Stock and Sandeep Subramanian and Sophia Yang and Szymon Antoniak and Teven Le Scao and Théophile Gervet and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2024},
      eprint={2401.04088},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{jiang2023mistral,
      title={Mistral 7B}, 
      author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
      year={2023},
      eprint={2310.06825},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{geminiteam2024gemini1.5,
      title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}, 
      author={Machel Reid and Nikolay Savinov and Denis Teplyashin and Dmitry and Lepikhin and Timothy Lillicrap and Jean-baptiste Alayrac and Radu Soricut and Angeliki Lazaridou and Orhan Firat and Julian Schrittwieser and Ioannis Antonoglou and Rohan Anil and Sebastian Borgeaud and Andrew Dai et al.},
      year={2024},
      eprint={2403.05530},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{gem1.0,
      title={Gemini: A Family of Highly Capable Multimodal Models}, 
      author={Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M. Dai and Anja Hauth et al.},
      year={2024},
      eprint={2312.11805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}



@misc{claude3,
    title={Introducing the next generation of Claude},
    author={Anthropic},
year = {2024},
    url = {https://www.anthropic.com/news/claude-3-family}
}


@misc{gpt4o,
    title={Hello GPT-4o},
    url={https://openai.com/index/hello-gpt-4o/},
    author={OpenAI},
    year={2024}
}

@misc{gpt3.5,
    title={Introducing ChatGPT},
    year = {2022},
    url = {https://openai.com/index/chatgpt/},
    author = {OpenAI},
}
@inproceedings{gray2024mobilizing,
  title={Mobilizing Research and Regulatory Action on Dark Patterns and Deceptive Design Practices},
  author={Gray, Colin M and Gunawan, Johanna T and Sch{\"a}fer, Ren{\'e} and Bielova, Nataliia and Sanchez Chamorro, Lorena and Seaborn, Katie and Mildner, Thomas and Sandhaus, Hauke},
  booktitle={Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
  pages={1--6},
  year={2024}
}

@misc{zhao2023survey,
      title={A Survey of Large Language Models}, 
      author={Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
      year={2023},
      eprint={2303.18223},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}

@misc{naveed2024comprehensive,
      title={A Comprehensive Overview of Large Language Models}, 
      author={Humza Naveed and Asad Ullah Khan and Shi Qiu and Muhammad Saqib and Saeed Anwar and Muhammad Usman and Naveed Akhtar and Nick Barnes and Ajmal Mian},
      year={2024},
      eprint={2307.06435},
      archivePrefix={arXiv},
      primaryClass={id='cs.CL' full_name='Computation and Language' is_active=True alt_name='cmp-lg' in_archive='cs' is_general=False description='Covers natural language processing. Roughly includes material in ACM Subject Class I.2.7. Note that work on artificial languages (programming languages, logics, formal systems) that does not explicitly address natural-language issues broadly construed (natural-language processing, computational linguistics, speech, text retrieval, etc.) is not appropriate for this area.'}
}

@misc{artificialintelligenceactRecitalArtificial,
	author = {EU},
	year={2024},
title = {Recital 29 | EU Artificial Intelligence Act --- artificialintelligenceact.eu},
    url={https://artificialintelligenceact.eu/recital/29/},
}


@misc{ma2023understandingbenefitschallengesusing,
      title={Understanding the Benefits and Challenges of Using Large Language Model-based Conversational Agents for Mental Well-being Support}, 
      author={Zilin Ma and Yiyang Mei and Zhaoyuan Su},
      year={2023},
      eprint={2307.15810},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2307.15810}
}

@article{visser2024AlmostHuman,
author = {de Visser, Ewart and Monfort, Samuel and Mckendrick, Ryan and Smith, Melissa and Mcknight, Patrick and Krueger, Frank and Parasuraman, Raja},
year = {2016},
month = {08},
pages = {},
title = {Almost Human: Anthropomorphism Increases Trust Resilience in Cognitive Agents},
volume = {22},
journal = {Journal of Experimental Psychology: Applied},
doi = {10.1037/xap0000092}
}

@article{LiAnthropo,
title = {Anthropomorphism brings us closer: The mediating role of psychological distance in User–AI assistant interactions},
journal = {Computers in Human Behavior},
volume = {118},
pages = {106680},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106680},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221000029},
author = {Xinge Li and Yongjun Sung}
}

@inproceedings{ladak2024moralconsideration,
  author = {Ladak, Ali and Harris, Jamie and Anthis, Jacy Reese},
  title = {Which Artificial Intelligences Do People Care About Most? A Conjoint Experiment on Moral Consideration},
  booktitle = {CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  year = {2024},
  pages = {287:1--287:11},
  doi = {10.1145/3613904.3642403}
}

@article{lee2020chatbot,
  author = {Lee, Yi-Chieh and Yamashita, Naomi and Huang, Yun},
  title = {Designing a Chatbot as a Mediator for Promoting Deep Self-Disclosure to a Real Mental Health Professional},
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {4},
  number = {CSCW1},
  pages = {31:1--31:27},
  year = {2020},
  doi = {10.1145/3392836}
}

@article{maples2024loneliness,
  author = {Maples, B. and Cerit, M. and Vishwanath, A. and others},
  title = {Loneliness and suicide mitigation for students using GPT3-enabled chatbots},
  journal = {npj Mental Health Research},
  volume = {3},
  pages = {4},
  year = {2024},
  doi = {10.1038/s44184-023-00047-6},
  url = {https://doi.org/10.1038/s44184-023-00047-6}
}

@article{park2024human,
  author = {Park, G. and Chung, J. and Lee, S.},
  title = {Human vs. machine-like representation in chatbot mental health counseling: the serial mediation of psychological distance and trust on compliance intention},
  journal = {Current Psychology},
  volume = {43},
  pages = {4352--4363},
  year = {2024},
  doi = {10.1007/s12144-023-04653-7},
  url = {https://doi.org/10.1007/s12144-023-04653-7}
}

@article{wester2024chatbot,
  author = {Wester, Joel and Pohl, Henning and Hosio, Simo and van Berkel, Niels},
  title = {"This Chatbot Would Never...": Perceived Moral Agency of Mental Health Chatbots},
  journal = {Proceedings of the ACM on Human-Computer Interaction},
  volume = {8},
  number = {CSCW1},
  pages = {133:1--133:28},
  year = {2024},
  doi = {10.1145/3637410},
  url = {https://doi.org/10.1145/3637410}
}

@misc{oaiembeddings,
    author = {OpenAI},
    title = {New embedding models and API updates},
    url = {https://openai.com/index/new-embedding-models-and-api-updates/},
    year = {2024}
}